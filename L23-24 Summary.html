<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PSYC3016 - Lectures 23-24 Summary: Language Development II & III - Nativist vs. Constructionist</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 40px 20px;
            min-height: 100vh;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 50px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        h1 {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 20px;
            text-align: center;
            border-bottom: 4px solid #667eea;
            padding-bottom: 20px;
        }
        h2 {
            color: #34495e;
            font-size: 1.8em;
            margin: 30px 0 15px 0;
            padding: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
        }
        .question-box {
            background: #f8f9fa;
            border-left: 6px solid #3498db;
            padding: 25px;
            margin: 30px 0;
            border-radius: 8px;
            font-size: 1.15em;
            font-weight: 600;
            color: #2c3e50;
        }
        .summary-text {
            font-size: 1.1em;
            line-height: 2;
            text-align: justify;
            margin: 30px 0;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 10px;
        }
        .legend {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 30px 0;
            padding: 25px;
            background: #ecf0f1;
            border-radius: 10px;
        }
        .legend-item {
            padding: 12px;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.95em;
        }
        .nativist { background-color: #ffebee; }
        .constructionist { background-color: #e8f5e9; }
        .evidence { background-color: #fff3e0; }
        .mechanisms { background-color: #e1f5fe; }
        .critiques { background-color: #f3e5f5; }
        .key-concepts { background-color: #fff9c4; }

        @media print {
            body { background: white; padding: 0; }
            .container { box-shadow: none; padding: 20px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>PSYC3016 - Lectures 23-24: Language Development II & III<br><span style="font-size: 0.7em;">Nativist vs. Constructionist Approaches</span></h1>

        <div class="question-box">
            <strong>Overarching Question:</strong> How do children acquire the computational complexity of human syntax—through innate, language-specific constraints (nativism claiming Universal Grammar provides hierarchical phrase structure rules and structural dependence that cannot be learned from impoverished input) or through domain-general learning mechanisms (constructionism arguing statistical learning, analogical abstraction, and social reasoning suffice without genetically specified syntactic knowledge)—with the central hinge being whether early syntactic knowledge is verb-general and abstract from the start (supporting innate constraints) or lexically specific and gradually abstracted (supporting domain-general learning)?
        </div>

        <h2>Color-Coded Legend</h2>
        <div class="legend">
            <div class="legend-item nativist">Nativist Position: UG, innate constraints, structural dependence</div>
            <div class="legend-item constructionist">Constructionist Position: Statistical learning, gradual abstraction</div>
            <div class="legend-item evidence">Evidence/Studies: Experimental findings and numerical results</div>
            <div class="legend-item mechanisms">Mechanisms: How language learning operates</div>
            <div class="legend-item critiques">Critiques: Challenges to each position</div>
            <div class="legend-item key-concepts">Key Concepts: Critical frameworks and principles</div>
        </div>

        <h2>Comprehensive Summary</h2>
        <div class="summary-text">
            The <span class="nativist">nativist thesis, championed by Chomsky, holds that Universal Grammar (UG) provides hierarchical phrase structure rules (sentences decompose into Noun Phrase + Verb Phrase; VP = V + NP) and constraints like structural dependence</span>, which <span class="key-concepts">cannot be learned from input alone given the poverty of the stimulus</span>—adult speakers possess implicit knowledge of syntactic constraints appearing nowhere in child input, exemplified by <span class="evidence">wh-movement in questions like "Which movie does Susan imagine that Sarah saw <em>t</em> last night?" where movement is structure-dependent, not linear</span>, and children never receive <span class="key-concepts">negative evidence</span> (no ungrammatical sentences like "*What did Beth eat peanut butter and <em>t</em> for dinner?" to teach prohibitions) yet never make these errors, leading Chomsky to argue that if general learning mechanisms were sufficient, children should overgeneralize and produce such errors before correcting based on feedback—but they do not, therefore <span class="nativist">constraints on wh-movement must be part of innate UG specifying universally allowed versus prohibited syntactic operations across all human languages</span>. <span class="key-concepts">Structural dependence</span> is the principle that <span class="nativist">syntactic operations reference hierarchical phrase structure, not linear word order</span>, demonstrated in English question formation where the rule is not "move first auxiliary to sentence-initial position" but "move auxiliary in main clause VP to sentence-initial position": declarative "The boy who is smoking is crazy" yields correct question "Is the boy who is smoking crazy?" (moving main-clause "is") not "*Is the boy who smoking is crazy?" (moving first "is"), with <span class="evidence">Crain & Nakayama (1987) finding zero structural dependence violations across 600+ questions from 3-5 year-olds</span> despite relative clauses being rare in child-directed speech, representing <span class="key-concepts">poverty of stimulus</span> where if children were learning purely from input statistics they should initially hypothesize the simpler linear rule, make errors, then correct based on feedback, but <span class="evidence">perfect performance despite impoverished input</span> is taken as evidence that <span class="nativist">structural dependence is an innate schematism (Chomsky, 1971)—children never consider structure-independent rules because UG prohibits them</span>. <span class="nativist">Sensitive period effects</span> provide evidence for genetically programmed maturational constraints specific to language: <span class="evidence">deaf individuals not exposed to sign language before age 7 show permanent difficulties with complex syntax; those first exposed after puberty never achieve native fluency in grammatical morphology or embedding structures</span>, which cannot be explained by general cognitive decline with age (adults learn complex mathematics, chess, musical instruments), suggesting language-specific neural windows strengthened by <span class="evidence">Nicaraguan Sign Language emergence in the 1980s where first cohort invented home signs lacking full compositionality, but second cohort—children exposed to first-cohort signing before their sensitive period closed—systematically regularized and complexified the emerging language, introducing componential structure absent in input</span> as <span class="evidence">Senghas, Kita, & Özyürek (2004) documented: first-cohort signers produced 25% componential (sequential manner+path gestures) versus Spanish speakers' 65% simultaneous co-speech gestures, but second-cohort signers separated into 75% componential expressions and cohort 3 achieved 73% fully systematic componentiality</span>, with the <span class="evidence">dramatic increase from cohort 1 (25%) to cohort 2/3 (75%) occurring despite cohort 2 children having cohort 1 adults as primary models</span> suggesting children did not simply learn what was modeled but <span class="mechanisms">restructured input according to linguistic principles</span>, which nativists interpret as <span class="nativist">UG-driven where innate language faculty imposes compositionality, hierarchy, and systematicity even when absent in immediate environment, with sensitive period constraint explaining why first-cohort adults past their critical window could not generate these structures themselves</span>. <span class="nativist">Early abstraction accounts</span> (e.g., Gertner, Fisher, & Eisengart, 2006) propose that children possess <span class="key-concepts">innate verb-general knowledge linking syntactic positions to semantic roles: agents map to subjects (pre-verbal in English), patients map to objects (post-verbal), with one-to-one mapping principle where each semantic role requires a noun and each noun requires a semantic role</span>, explaining how <span class="evidence">21-month-olds use novel verbs productively: hearing "The frog is gorping the bear" (transitive syntax), children infer "gorp" describes agent-patient event and look longer at scenes where frog acts on bear versus mutual interaction</span>, which cannot be lexically specific (never heard "gorp") nor purely statistical (both scenes equally plausible), leading early abstraction accounts to claim children start with <span class="mechanisms">abstract semantic-syntactic correspondences, not item-based schemas</span>, though still must learn language-specific word orders through distributional analysis—this position is weaker than full UG (no innate phrase structure) but stronger than pure constructivism (not all abstraction is gradual). The <span class="constructionist">constructionist counterthesis (Tomasello, 2003; Ambridge, 2020) argues that domain-general cognitive mechanisms—statistical learning, analogical abstraction, social reasoning—suffice to account for language acquisition without invoking genetically specified syntactic knowledge</span>, with core premises that <span class="constructionist">(1) linguistic input is far richer than nativists acknowledge (children hear millions of utterances with systematic distributional patterns), (2) modern learning mechanisms (neural networks tracking multi-order transitional probabilities, relational structure mapping) are more powerful than associative learning Chomsky dismissed in 1950s, and (3) poverty of stimulus is artifact of underestimating what information is available and extractable from naturalistic input</span>, critically noting that while humans have genetic adaptations enabling language (vocal tract anatomy, auditory processing, social cognition, memory capacity), <span class="constructionist">these adaptations are domain-general: same mechanisms enabling language also support learning baseball, mathematics, social norms, with language-specific constraints being emergent properties of applying general learning to structured domain of linguistic communication, not pre-specified architectural modules</span>, explaining why <span class="evidence">large language models like GPT, trained purely on distributional statistics without innate grammar rules, can generate syntactically complex, contextually appropriate language demonstrating statistical learning from rich input can in principle acquire syntax</span>. <span class="constructionist">Three core constructionist claims</span>: <span class="mechanisms">(1) Distributional statistics reveal grammatical categories where children track transitional probabilities (how likely syllable B follows A) and distributional contexts (which words appear in frame "the ___ is")</span>, with <span class="evidence">Mintz (2003) showing frequent frames in child-directed speech (e.g., "you ___ it," "the ___ is") reliably group words into syntactic categories with 87% accuracy for nouns in frame "the ___ is"</span>, providing sufficient information to bootstrap noun/verb distinctions purely from co-occurrence statistics; <span class="constructionist">(2) Abstract constructions are built gradually where children's earliest syntactic knowledge is lexically specific</span> ("Kick X," "Throw Y") not abstract (SUBJECT VERB OBJECT), with <span class="mechanisms">analogical comparison across item-based schemas ("I kick ball," "I hit ball," "I throw ball") extracting common relational structure ([AGENT] [ACTION] [PATIENT]) to gradually form verb-general constructions</span>, evidenced by <span class="evidence">Tomasello & Brooks (1998) finding 2-year-olds taught novel verb in intransitive frames ("The sock is tamming") failing to use it transitively ("He's tamming the sock") with only 3/16 children aged 2;0 (7/16 at 2;6) producing transitive, but 4-year-olds succeeding readily</span>, suggesting verb-island schemas not abstract rules; and <span class="constructionist">(3) Errors occur when statistics support them, contra UG predictions</span>, as <span class="evidence">Ambridge et al. (2008) found 7% structural dependence errors in "can" questions ("Can the boy who smoke can drive?") but 0% in "is" questions because "who smoke" is grammatical pair (people who smoke) whereas "who smoking" never occurs</span>, with this <span class="critiques">word-specific variability contradicting UG's claim of universal innate constraints</span>. <span class="mechanisms">Statistical learning</span> was demonstrated by <span class="evidence">Saffran, Aslin, & Newport (1996) showing 8-month-old infants segment continuous speech streams using transitional probability (TP) information</span> where infants heard 2 minutes of synthesized speech concatenating pseudowords (bidaku-padoti-golabu-bidaku...) with no pauses, and <span class="evidence">within-word TPs were 1.0 (after "bi," "da" always followed) while across-boundary TPs dropped to 0.33 (after "ku," any of three syllables could follow)</span>, with test showing <span class="evidence">infants preferred novel "non-words" (kupado spanning boundaries) over "words" (bidaku)</span>, demonstrating extraction of word units purely from TP dips, arguing against poverty-of-stimulus claim since infants do not require word boundaries marked by prosody or pauses but can infer segmentation from statistical regularities, critically representing <span class="mechanisms">domain-general statistical learning—similar mechanisms extract patterns from visual sequences, tonal sequences, motor actions</span>, undermining nativist arguments that language-specific constraints are necessary to solve segmentation. <span class="constructionist">Tomasello's (2003) gradual abstraction account</span> rejects the claim that children start with abstract syntactic categories (SUBJECT, VERB, OBJECT), instead proposing <span class="key-concepts">early syntactic knowledge is verb-specific: children initially learn "kick" appears in frames like "I kick X," producing verb-island schemas tied to individual lexical items</span>, with abstract constructions emerging slowly through <span class="mechanisms">schematization—detecting commonalities across multiple item-based schemas via analogical comparison</span> following developmental trajectory: <span class="evidence">(1) wholly concrete (18-24 months): "I kick it," "I kick ball" (rote-learned exemplars); (2) item-specific schema (24-30 months): "I kick [OBJECT]" (variable slot for objects with specific verb); (3) verb-class schema (30-36 months): "I [ACTION] [OBJECT]" (kick, hit, throw—partially abstract); (4) fully abstract (36+ months): "[SUBJECT] [VERB] [OBJECT]" (any verb, full productivity)</span>, with <span class="evidence">age-graded performance suggesting children do not initially possess abstract transitive syntax but must accumulate exemplars then generalize, while same children readily used novel nouns in diverse constructions ("I want toma," "I see toma") showing conservatism is syntax-specific, not general shyness or task demands</span>. However, <span class="critiques">Dittmar, Abbot-Smith, Lieven, & Tomasello (2008) identified critical confound in Fisher's study: children were "warmed up" with familiar verbs in transitive frames using exact nouns from test trials ("The frog is washing the bear"), potentially priming item-specific frames ([FROG] [VERB] [BEAR]) not abstract syntax</span>, and when <span class="evidence">Dittmar et al. replicated Fisher's procedure but replaced transitive warm-ups with generic descriptions ("This is called washing") avoiding transitive syntax and specific noun combinations, children in control condition failed—no longer showed agent-patient looking preferences despite identical test trials</span>, demonstrating that <span class="critiques">Fisher's evidence for abstract syntax depends on specific prior exposure to relevant nouns in transitive contexts, consistent with exemplar-based retrieval rather than abstract schema activation</span>, with the argument being not that 21-month-olds have zero syntactic knowledge but that their knowledge is <span class="constructionist">exemplar-based and context-dependent, requiring structural priming to manifest rather than being freely applicable abstract rules</span>, leaving the debate unresolved where <span class="nativist">nativists claim priming merely "unlocks" pre-existing abstract knowledge (performance facilitation)</span> while <span class="constructionist">constructionists claim priming constitutes the basis for generalization (competence itself is exemplar-grounded)</span>, ultimately establishing that language acquisition debate centers on whether early syntactic competence reflects <span class="key-concepts">verb-general abstract knowledge present from onset of multi-word speech supporting innate UG versus verb-specific item-based schemas gradually abstracting to constructions supporting domain-general learning</span>, with critical empirical hinges including <span class="key-concepts">(1) whether children make structural dependence errors when statistics support them (Ambridge's 7% with "can" vs. 0% with "is" challenges UG universality), (2) whether sensitive periods and language generation are language-specific or domain-general (NSL evidence debated), (3) whether 21-month-olds extend novel verbs without priming (Fisher: yes; Dittmar: no when priming removed), and (4) whether verb frequency interacts with construction generalization (if yes, supports item-based learning; if no, supports abstract knowledge with retrieval effects)</span>, collectively demonstrating that nativism posits <span class="nativist">language-specific innate knowledge (phrase structure rules, structural dependence, recursion, universal constraints) with abstract verb-general initial state where children represent syntactic categories from onset around 18 months, with structural dependence as innate UG constraint and sensitive periods reflecting language-specific critical periods tied to UG maturation</span>, while constructionism proposes <span class="constructionist">domain-general mechanisms (statistical learning, analogical abstraction, working memory, social cognition) without language-specific architectural constraints, with concrete item-specific initial state where children represent verb islands gradually abstracting to schemas through exemplar comparison around 36+ months, with structural dependence emergent from transitional probabilities and sensitive periods reflecting domain-general neural plasticity decline</span>, with the overarching question remaining whether language represents specialized cognitive module with innate constraints or emergent property of general cognition applied to rich linguistic input, hinging fundamentally on whether the speed and systematicity of child language acquisition requires pre-specified grammatical architecture or can be explained by powerful domain-general learning operating on informationally rich distributional, prosodic, and social-pragmatic cues available in naturalistic linguistic environments.
        </div>

        <div style="margin-top: 40px; padding: 20px; background: #ecf0f1; border-radius: 10px; text-align: center;">
            <p style="color: #7f8c8d; font-size: 0.9em;">
                <strong>File Location:</strong> /Users/oisheyhossain/Desktop/3016/L23-24_Summary.html
            </p>
            <p style="color: #7f8c8d; font-size: 0.9em; margin-top: 10px;">
                PSYC3016 - Developmental Psychology • Lectures 23-24: Language Development II & III
            </p>
        </div>
    </div>
</body>
</html>